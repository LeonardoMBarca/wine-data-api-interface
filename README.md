# ğŸ‡ Tech Challenge FIAP - API para Dados VitivinÃ­colas

![Embrapa Uva e Vinho](https://img.shields.io/badge/Embrapa-Uva%20e%20Vinho-brightgreen)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Flask](https://img.shields.io/badge/Flask-2.0%2B-lightblue)
![Status](https://img.shields.io/badge/Status-MVP-orange)

Uma API REST completa para coleta, processamento e disponibilizaÃ§Ã£o de dados vitivinÃ­colas da Embrapa, com pipeline ETL automatizado e dashboard de visualizaÃ§Ã£o.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Arquitetura](#-arquitetura)
- [Funcionalidades](#-funcionalidades)
- [ConfiguraÃ§Ã£o e InstalaÃ§Ã£o](#-configuraÃ§Ã£o-e-instalaÃ§Ã£o)
- [Executando o Projeto](#-executando-o-projeto)
- [API Endpoints](#-api-endpoints)
- [Dashboard](#-dashboard)
- [Pipeline de Dados](#-pipeline-de-dados)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [CenÃ¡rios de Uso com Machine Learning](#-cenÃ¡rios-de-uso-com-machine-learning)
- [ContribuiÃ§Ã£o](#-contribuiÃ§Ã£o)
- [LicenÃ§a](#-licenÃ§a)

## ğŸ” VisÃ£o Geral

Este projeto Ã© uma soluÃ§Ã£o completa para coleta, processamento e disponibilizaÃ§Ã£o de dados vitivinÃ­colas da Embrapa. A arquitetura inclui:

- **API REST** com autenticaÃ§Ã£o JWT
- **Crawler** automatizado para coleta de dados
- **Pipeline ETL** com camadas Bronze, Silver e Gold
- **Dashboard** interativo para visualizaÃ§Ã£o de dados
- **DocumentaÃ§Ã£o Swagger** para facilitar o uso da API

Os dados coletados incluem informaÃ§Ãµes sobre produÃ§Ã£o, processamento, comercializaÃ§Ã£o, importaÃ§Ã£o e exportaÃ§Ã£o de uvas, vinhos e derivados no Brasil.

## ğŸ—ï¸ Arquitetura

O sistema segue uma arquitetura moderna de processamento de dados:

![Arquitetura](imgs/arquitetura.png)

1. **Camada de Coleta (Crawler)**: Extrai dados do site da Embrapa
2. **Camada de Processamento (ETL)**:
   - **Bronze**: Dados brutos como coletados
   - **Silver**: Dados limpos e padronizados
   - **Gold**: Dados curados e prontos para anÃ¡lise
   - **Analytics**: Dados agregados para visualizaÃ§Ã£o
3. **Camada de ExposiÃ§Ã£o**:
   - **API REST**: Endpoints para consumo dos dados
   - **Dashboard**: Interface visual para anÃ¡lise

## âš™ï¸ Funcionalidades

### ğŸ” AutenticaÃ§Ã£o

- Sistema de autenticaÃ§Ã£o JWT para proteÃ§Ã£o dos endpoints
- Tokens com validade de 30 minutos
- Login simplificado para o dashboard

### ğŸ•·ï¸ Crawler Automatizado

- Coleta dados diretamente do site da Embrapa
- Verifica disponibilidade dos links antes de iniciar o download
- Sistema de logs para monitoramento do processo

### ğŸ”„ Pipeline ETL

- Processamento completo dos dados em trÃªs camadas
- TransformaÃ§Ãµes especÃ­ficas para cada tipo de dado
- GeraÃ§Ã£o de datasets analÃ­ticos para visualizaÃ§Ã£o

### ğŸ“Š Dashboard Interativo

- VisualizaÃ§Ã£o dos dados por categoria
- Filtros dinÃ¢micos por ano, paÃ­s, categoria, etc.
- GrÃ¡ficos interativos para anÃ¡lise de tendÃªncias
- **BotÃ£o de atualizaÃ§Ã£o de dados** que executa o crawler e os pipelines ETL em tempo real
- Feedback visual sobre o status da atualizaÃ§Ã£o, incluindo mensagem de erro caso o site da Embrapa esteja indisponÃ­vel

### ğŸ“¡ API REST

- Endpoints para consulta de dados por categoria e subcategoria
- DocumentaÃ§Ã£o Swagger integrada
- ExecuÃ§Ã£o automÃ¡tica do pipeline a cada consulta (para fins de demonstraÃ§Ã£o)

## ğŸ› ï¸ ConfiguraÃ§Ã£o e InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)
- Git

### 1. Clonar o RepositÃ³rio

```bash
git clone https://github.com/seu-usuario/tech-challenge-fiap-machine-learning-api.git
cd tech-challenge-fiap-machine-learning-api
```

### 2. Criar e Ativar Ambiente Virtual

#### Windows

```bash
python -m venv venv
venv\Scripts\activate
```

#### Linux/Mac

```bash
python -m venv venv
source venv/bin/activate
```

### 3. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 4. ConfiguraÃ§Ã£o de VariÃ¡veis de Ambiente (Opcional)

O projeto estÃ¡ configurado para funcionar com valores padrÃ£o, mas vocÃª pode personalizar as chaves de seguranÃ§a criando um arquivo `.env` na raiz do projeto:

```
JWT_SECRET_KEY=sua_chave_secreta_para_jwt
FLASK_SECRET_KEY=sua_chave_secreta_para_flask_session
```

Se nÃ£o for criado, o sistema usarÃ¡ chaves padrÃ£o definidas no cÃ³digo.

## ğŸš€ Executando o Projeto

### Iniciar a API e o Dashboard

```bash
python -m api.app
```

O servidor estarÃ¡ disponÃ­vel em:

- API: `http://127.0.0.1:5000/data/`
- Dashboard: `http://127.0.0.1:5000/`
- DocumentaÃ§Ã£o Swagger: `http://127.0.0.1:5000/apidocs/`

### AutenticaÃ§Ã£o

Entrando no Dashboard serÃ¡ solicitado usuÃ¡rio e senha. Caso nÃ£o tenha feito a criaÃ§Ã£o do arquivo para as variÃ¡veis de ambiente como o indicado, faÃ§a a utilizaÃ§Ã£o das seguintes credenciais para ter acesso ao dashboard:

User: admin

Password: demonstracao

### AutenticaÃ§Ã£o

POST /auth/login

```
{
  "username": "user",
  "password": "user"
}
```

**Resposta**:

```json
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
}
```

### Executar Crawler Manualmente

```
POST /crawler/executar
```

**Header**:

```
Authorization: Bearer <seu_token>
```

### Consultar Dados

```
GET /data/<categoria>/<subcategoria>
```

**Categorias disponÃ­veis**:

- `exportacao`
- `importacao`
- `processamento`
- `comercializacao`
- `producao`

**Subcategorias por categoria**:


| Categoria       | Subcategorias                             |
| --------------- | ----------------------------------------- |
| exportacao      | espumantes, suco, uva, vinho              |
| importacao      | espumantes, frescas, passas, suco, vinhos |
| processamento   | americanas, mesa, semclass, viniferas     |
| comercializacao | default                                   |
| producao        | default                                   |

**Header**:

```
Authorization: Bearer <seu_token>
```

**Exemplo de resposta**:

```json
{
  "mensagem": "Dados de exportacao/suco carregados com sucesso!",
  "usuario": "user",
  "dados": [
    {"pais": "alemanha", "ano": 1970, "kilograms": 0, "dollars": 0},
    {"pais": "brasil", "ano": 1971, "kilograms": 100, "dollars": 2000}
  ]
}
```

## ğŸ–¥ï¸ Dashboard

O dashboard oferece uma interface visual para anÃ¡lise dos dados coletados e processados.

### Acesso

URL: `http://127.0.0.1:5000/`

**Credenciais**:

- UsuÃ¡rio: `admin`
- Senha: `demonstracao`

### PÃ¡ginas DisponÃ­veis

- **ComercializaÃ§Ã£o**: Dados sobre comercializaÃ§Ã£o de produtos vitivinÃ­colas
- **ExportaÃ§Ã£o**: Dados sobre exportaÃ§Ã£o de vinhos, sucos, uvas e espumantes
- **ImportaÃ§Ã£o**: Dados sobre importaÃ§Ã£o de vinhos, sucos, uvas frescas, passas e espumantes
- **Processamento**: Dados sobre processamento de uvas por tipo e classificaÃ§Ã£o
- **ProduÃ§Ã£o**: Dados sobre produÃ§Ã£o de uvas e derivados

Cada pÃ¡gina possui filtros dinÃ¢micos baseados nos dados disponÃ­veis, como ano, paÃ­s, categoria, etc.

### AtualizaÃ§Ã£o de Dados em Tempo Real

O dashboard inclui um botÃ£o "Atualizar Dados" que permite:

1. Executar o crawler para baixar os dados mais recentes do site da Embrapa
2. Processar automaticamente os dados atravÃ©s do pipeline ETL completo:
   - Bronze Layer: Armazenamento dos dados brutos
   - Silver Layer: Limpeza e padronizaÃ§Ã£o
   - Gold Layer: Curadoria final para anÃ¡lise

Se o site da Embrapa estiver indisponÃ­vel, o sistema exibirÃ¡ a mensagem "Site da Embrapa se encontra indisponÃ­vel no momento" e manterÃ¡ os dados existentes.

## ğŸ“Š Pipeline de Dados

O pipeline de dados segue uma arquitetura de trÃªs camadas:

### 1. Bronze Layer (Dados Brutos)

- Dados coletados diretamente do site da Embrapa
- Formato original sem transformaÃ§Ãµes
- Armazenados em `data/bronze-layer/`

### 2. Silver Layer (Dados Limpos)

- Dados com tratamento inicial
- PadronizaÃ§Ã£o de formatos e nomes de colunas
- RemoÃ§Ã£o de inconsistÃªncias
- Armazenados em `data/silver-layer/`

### 3. Gold Layer (Dados Curados)

- Dados completamente processados
- Enriquecidos com informaÃ§Ãµes adicionais
- Prontos para anÃ¡lise e visualizaÃ§Ã£o
- Armazenados em `data/gold-layer/`

### 4. Analytics Layer (Dados Agregados)

- Dados agregados para visualizaÃ§Ã£o no dashboard
- Otimizados para consultas rÃ¡pidas
- Armazenados em `data/analytics/`

## ğŸ“ Estrutura do Projeto

```
tech-challenge-fiap-machine-learning-api/
â”œâ”€â”€ api/                           # API REST
â”‚   â”œâ”€â”€ app.py                     # ConfiguraÃ§Ã£o da API
â”‚   â””â”€â”€ routes/                    # Rotas da API
â”‚       â”œâ”€â”€ auth_routes.py         # AutenticaÃ§Ã£o
â”‚       â”œâ”€â”€ crawler_routes.py      # ExecuÃ§Ã£o do crawler
â”‚       â””â”€â”€ data_routes.py         # Consulta de dados
â”‚
â”œâ”€â”€ crawler/                       # MÃ³dulo de coleta de dados
â”‚   â”œâ”€â”€ logs/                      # Logs do crawler
â”‚   â”œâ”€â”€ scraper/                   # Scripts de coleta
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ downloader.py          # Download dos dados
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                  # ConfiguraÃ§Ãµes do crawler
â”‚   â”œâ”€â”€ main.py                    # Ponto de entrada
â”‚   â””â”€â”€ README.MD                  # DocumentaÃ§Ã£o do crawler
â”‚
â”œâ”€â”€ dashboard/                     # Interface visual
â”‚   â”œâ”€â”€ static/                    # Arquivos estÃ¡ticos
â”‚   â”‚   â”œâ”€â”€ css/                   # Estilos
â”‚   â”‚   â””â”€â”€ js/                    # Scripts
â”‚   â”œâ”€â”€ templates/                  # Templates HTML
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ auth_config.py             # ConfiguraÃ§Ã£o de autenticaÃ§Ã£o
â”‚   â””â”€â”€ routes.py                  # Rotas do dashboard
â”‚
â”œâ”€â”€ data/                          # Armazenamento de dados
â”‚   â”œâ”€â”€ analytics/                 # Dados para visualizaÃ§Ã£o
â”‚   â”œâ”€â”€ bronze-layer/              # Dados brutos
â”‚   â”œâ”€â”€ silver-layer/              # Dados limpos
â”‚   â””â”€â”€ gold-layer/                # Dados curados
â”‚
â”œâ”€â”€ pipelines/                     # Pipelines ETL
â”‚   â””â”€â”€ etl/
â”‚       â”œâ”€â”€ bronze_to_silver/      # TransformaÃ§Ã£o Bronze â†’ Silver
â”‚       â”œâ”€â”€ silver_to_gold/        # TransformaÃ§Ã£o Silver â†’ Gold
â”‚       â””â”€â”€ gold_to_analytics/     # TransformaÃ§Ã£o Gold â†’ Analytics
â”‚
â”œâ”€â”€ .gitignore                     # Arquivos ignorados pelo Git
â”œâ”€â”€ app.py                         # Ponto de entrada principal
â”œâ”€â”€ LICENSE                        # LicenÃ§a do projeto
â”œâ”€â”€ Procfile                       # ConfiguraÃ§Ã£o para deploy
â”œâ”€â”€ README.md                      # Este arquivo
â””â”€â”€ requirements.txt               # DependÃªncias do projeto
```

## ğŸ§  CenÃ¡rios de Uso com Machine Learning

Esta API foi projetada para alimentar modelos de machine learning para anÃ¡lise e previsÃ£o de dados vitivinÃ­colas. Alguns cenÃ¡rios possÃ­veis:

### PrevisÃ£o de ProduÃ§Ã£o

- Modelos de sÃ©ries temporais para prever a produÃ§Ã£o de uvas por tipo
- AnÃ¡lise de fatores climÃ¡ticos e seu impacto na produÃ§Ã£o

### AnÃ¡lise de Mercado

- PrevisÃ£o de tendÃªncias de exportaÃ§Ã£o e importaÃ§Ã£o
- IdentificaÃ§Ã£o de mercados emergentes para vinhos brasileiros

### OtimizaÃ§Ã£o de Processamento

- Modelos para otimizar o processamento de diferentes tipos de uva
- PrevisÃ£o de demanda para ajuste de capacidade produtiva

### AnÃ¡lise de PreÃ§os

- Modelos para prever flutuaÃ§Ãµes de preÃ§os no mercado internacional
- IdentificaÃ§Ã£o de fatores que influenciam os preÃ§os de exportaÃ§Ã£o

**Nota**: Em um ambiente de produÃ§Ã£o, o pipeline seria executado por agendamento (usando ferramentas como Airflow, Jenkins ou cron), e nÃ£o a cada consulta como implementado neste MVP.

# 

Desenvolvido como parte do Tech Challenge da FIAP - PÃ³s-GraduaÃ§Ã£o em Machine Learning Engineering.
